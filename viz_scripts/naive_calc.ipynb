{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd2637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scaffolding\n",
    "from collections import defaultdict\n",
    "import naive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a5687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur = pd.read_csv(r'auxiliary_files/purpose_labels.csv')\n",
    "df_re = pd.read_csv(r'auxiliary_files/mode_labels.csv')\n",
    "df_ei = pd.read_csv(r'auxiliary_files/energy_intensity.csv')\n",
    "\n",
    "#dictionaries:\n",
    "dic_pur = dict(zip(df_pur['purpose_confirm'],df_pur['bin_purpose'])) # bin purpose\n",
    "dic_re  = dict(zip(df_re['replaced_mode'],df_re['mode_clean'])) # bin modes\n",
    "dic_fuel = dict(zip(df_ei['mode'],df_ei['fuel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6de8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "# please run that notebook first\n",
    "%store -r df_ei\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "%store -r dic_fuel\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)\n",
    "dic_fuel = defaultdict(lambda: 'Other',dic_fuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06cbaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('viz_scripts/abby_ceo/sc/analysis_confirmed_trip.csv')\n",
    "# we are using smart commute data. zip with this csv taken from onedrive.\n",
    "df = pd.read_csv('abby_ceo/sc/analysis_confirmed_trip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a18e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_traceback_handler(exception_type, exception, traceback):\n",
    "    print(\"%s: %s\" % (exception_type.__name__, exception), file=sys.stderr)\n",
    "\n",
    "def get_time_query(year, month):\n",
    "    if year is None and month is None:\n",
    "        return None\n",
    "\n",
    "    if month is None:\n",
    "        assert year is not None\n",
    "        query_ld = ecwl.LocalDate({\"year\": year})\n",
    "    else:\n",
    "        assert year is not None and month is not None\n",
    "        query_ld = ecwl.LocalDate({\"year\": year, \"month\": month})\n",
    "    tq = esttc.TimeComponentQuery(\"data.start_local_dt\", query_ld, query_ld)\n",
    "    return tq\n",
    "\n",
    "def get_participant_uuids(program, load_test_users):\n",
    "    \"\"\"\n",
    "        Get the list of non-test users in the current program.\n",
    "        Note that the \"program\" parameter is currently a NOP and should be removed in\n",
    "        conjunction with modifying the notebooks.\n",
    "    \"\"\"\n",
    "    all_users = pd.json_normalize(list(edb.get_uuid_db().find()))\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if len(all_users) == 0:\n",
    "        return []\n",
    "    if load_test_users:\n",
    "        participant_list = all_users\n",
    "    else:\n",
    "        participant_list = all_users[np.logical_not(all_users.user_email.str.contains(\"_test_\"))]\n",
    "    participant_uuid_str = participant_list.uuid\n",
    "    disp.display(participant_list.user_email)\n",
    "    return participant_uuid_str\n",
    "\n",
    "def load_all_confirmed_trips(tq):\n",
    "    agg = esta.TimeSeries.get_aggregate_time_series()\n",
    "    all_ct = agg.get_data_df(\"analysis/confirmed_trip\", tq)\n",
    "    print(\"Loaded all confirmed trips of length %s\" % len(all_ct))\n",
    "    disp.display(all_ct.head())\n",
    "    return all_ct\n",
    "\n",
    "def load_all_participant_trips(program, tq, load_test_users):\n",
    "    participant_list = get_participant_uuids(program, load_test_users)\n",
    "    all_ct = load_all_confirmed_trips(tq)\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if len(all_ct) == 0:\n",
    "        return all_ct\n",
    "    participant_ct_df = all_ct[all_ct.user_id.isin(participant_list)]\n",
    "    print(\"After filtering, found %s participant trips \" % len(participant_ct_df))\n",
    "    disp.display(participant_ct_df.head())\n",
    "    return participant_ct_df\n",
    "\n",
    "def filter_labeled_trips(mixed_trip_df):\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if len(mixed_trip_df) == 0:\n",
    "        return mixed_trip_df\n",
    "    labeled_ct = mixed_trip_df[mixed_trip_df.user_input != {}]\n",
    "    print(\"After filtering, found %s labeled trips\" % len(labeled_ct))\n",
    "    disp.display(labeled_ct.head())\n",
    "    return labeled_ct\n",
    "\n",
    "def expand_userinputs(labeled_ct):\n",
    "    '''\n",
    "    param: labeled_ct: a dataframe of confirmed trips, some of which have labels\n",
    "    params: labels_per_trip: the number of labels for each trip.\n",
    "        Currently, this is 2 for studies and 3 for programs, and should be \n",
    "        passed in by the notebook based on the input config.\n",
    "        If used with a trip-level survey, it could be even larger.\n",
    "    '''\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if len(labeled_ct) == 0:\n",
    "        return labeled_ct\n",
    "    label_only = pd.DataFrame(labeled_ct.user_input.to_list(), index=labeled_ct.index)\n",
    "    disp.display(label_only.head())\n",
    "    labels_per_trip = len(label_only.columns)\n",
    "    print(\"Found %s columns of length %d\" % (label_only.columns, labels_per_trip))\n",
    "    expanded_ct = pd.concat([labeled_ct, label_only], axis=1)\n",
    "    assert len(expanded_ct) == len(labeled_ct), \\\n",
    "        (\"Mismatch after expanding labels, expanded_ct.rows = %s != labeled_ct.rows %s\" %\n",
    "            (len(expanded_ct), len(labeled_ct)))\n",
    "    print(\"After expanding, columns went from %s -> %s\" %\n",
    "        (len(labeled_ct.columns), len(expanded_ct.columns)))\n",
    "    assert len(expanded_ct.columns) == len(labeled_ct.columns) + labels_per_trip, \\\n",
    "        (\"Mismatch after expanding labels, expanded_ct.columns = %s != labeled_ct.columns %s\" %\n",
    "            (len(expanded_ct.columns), len(labeled_ct.columns)))\n",
    "    disp.display(expanded_ct.head())\n",
    "    return expanded_ct\n",
    "\n",
    "# CASE 2 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "unique_users = lambda df: len(df.user_id.unique()) if \"user_id\" in df.columns else 0\n",
    "trip_label_count = lambda s, df: len(df[s].dropna()) if s in df.columns else 0\n",
    "\n",
    "def load_viz_notebook_data(year, month, program, study_type, dic_re, dic_pur=None, include_test_users=False):\n",
    "    \"\"\" Inputs:\n",
    "    year/month/program/study_type = parameters from the visualization notebook\n",
    "    dic_* = label mappings; if dic_pur is included it will be used to recode trip purpose\n",
    "    \n",
    "    Pipeline to load and process the data before use in visualization notebooks.\n",
    "    \"\"\"\n",
    "    # Access database\n",
    "    expanded_ct=pd.read_csv(to_data_folder + \"/filtered_merged_trips.csv\")\n",
    "    tq = get_time_query(year, month)\n",
    "    participant_ct_df = load_all_participant_trips(program, tq, include_test_users)\n",
    "    labeled_ct = filter_labeled_trips(participant_ct_df)\n",
    "    expanded_ct = expand_userinputs(labeled_ct)\n",
    "    expanded_ct = data_quality_check(expanded_ct)\n",
    "    \n",
    "\n",
    "    # Change meters to miles\n",
    "    # CASE 2 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if \"distance\" in expanded_ct.columns:\n",
    "        unit_conversions(expanded_ct)\n",
    "\n",
    "    # Mapping new mode labels with dictionaries\n",
    "    # CASE 2 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if \"mode_confirm\" in expanded_ct.columns:\n",
    "        expanded_ct['Mode_confirm']= expanded_ct['mode_confirm'].map(dic_re)\n",
    "    if study_type == 'program':\n",
    "        # CASE 2 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "        if 'replaced_mode' in expanded_ct.columns:\n",
    "            expanded_ct['Replaced_mode']= expanded_ct['replaced_mode'].map(dic_re)\n",
    "        else:\n",
    "            print(\"This is a program, but no replaced modes found. Likely cold start case. Ignoring replaced mode mapping\")\n",
    "    else:\n",
    "            print(\"This is a study, not expecting any replaced modes.\")\n",
    "\n",
    "    # Trip purpose mapping\n",
    "    # CASE 2 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if dic_pur is not None and \"purpose_confirm\" in expanded_ct.columns:\n",
    "        expanded_ct['Trip_purpose']= expanded_ct['purpose_confirm'].map(dic_pur)\n",
    "\n",
    "    # Document data quality\n",
    "    file_suffix = get_file_suffix(year, month, program)\n",
    "    quality_text = get_quality_text(participant_ct_df, expanded_ct, None, include_test_users)\n",
    "\n",
    "    debug_df = pd.DataFrame.from_dict({\n",
    "            \"year\": year,\n",
    "            \"month\": month,\n",
    "            \"Registered_participants\": len(get_participant_uuids(program, include_test_users)),\n",
    "            \"Participants_with_at_least_one_trip\": unique_users(participant_ct_df),\n",
    "            \"Participant_with_at_least_one_labeled_trip\": unique_users(labeled_ct),\n",
    "            \"Trips_with_at_least_one_label\": len(labeled_ct),\n",
    "            \"Trips_with_mode_confirm_label\": trip_label_count(\"Mode_confirm\", expanded_ct),\n",
    "            \"Trips_with_trip_purpose_label\": trip_label_count(\"Trip_purpose\", expanded_ct)\n",
    "            },\n",
    "        orient='index', columns=[\"value\"])\n",
    "\n",
    "    return expanded_ct, file_suffix, quality_text, debug_df\n",
    "\n",
    "def add_energy_labels(expanded_ct, df_ei, dic_fuel):\n",
    "    \"\"\" Inputs:\n",
    "    expanded_ct = dataframe of trips that has had Mode_confirm and Replaced_mode added\n",
    "    dic/df_* = label mappings for energy impact and fuel\n",
    "    \"\"\"\n",
    "    expanded_ct['Mode_confirm_fuel']= expanded_ct['Mode_confirm'].map(dic_fuel)\n",
    "    expanded_ct = energy_intensity(expanded_ct, df_ei, 'Mode_confirm')\n",
    "    expanded_ct = energy_footprint_kWH(expanded_ct, 'distance_miles', 'Mode_confirm')\n",
    "    expanded_ct = CO2_footprint_lb(expanded_ct, 'distance_miles', 'Mode_confirm')\n",
    "    return expanded_ct\n",
    "\n",
    "def add_energy_impact(expanded_ct, df_ei, dic_fuel):\n",
    "    # Let's first calculate everything for the mode confirm\n",
    "    # And then calculate everything for the replaced mode\n",
    "    expanded_ct = add_energy_labels(expanded_ct, df_ei, dic_fuel)\n",
    "    expanded_ct['Replaced_mode_fuel']= expanded_ct['Replaced_mode'].map(dic_fuel)\n",
    "    expanded_ct = energy_intensity(expanded_ct, df_ei, 'Replaced_mode')\n",
    "    # and then compute the impacts\n",
    "    expanded_ct = energy_impact_kWH(expanded_ct, 'distance_miles')\n",
    "    expanded_ct = CO2_impact_lb(expanded_ct, 'distance_miles')\n",
    "    return expanded_ct\n",
    "\n",
    "def get_quality_text(before_df, after_df, mode_of_interest=None, include_test_users=False):\n",
    "    \"\"\" Inputs:\n",
    "    before_df = dataframe prior to filtering (usually participant_ct_df)\n",
    "    after_df = dataframe after filtering (usually expanded_ct)\n",
    "    mode_of_interest = optional detail to include in the text string\n",
    "    \"\"\"\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    after_pct = (len(after_df) * 100) / len(before_df) if len(before_df) != 0 else np.nan\n",
    "    cq = (len(after_df), unique_users(after_df), len(before_df), unique_users(before_df),\n",
    "        after_pct, )\n",
    "    interest_str = mode_of_interest + ' ' if mode_of_interest is not None else ''\n",
    "    total_str = 'confirmed' if mode_of_interest is not None else ''\n",
    "    user_str = 'testers and participants' if include_test_users else 'users'\n",
    "    quality_text = f\"Based on %s confirmed {interest_str}trips from %d {user_str}\\nof %s total {total_str} trips from %d users (%.2f%%)\" % cq\n",
    "    print(quality_text)\n",
    "    return quality_text\n",
    "\n",
    "def get_file_suffix(year, month, program):\n",
    "    suffix = \"_%04d\" % year if year is not None else \"\"\n",
    "    suffix = suffix + \"_%02d\" % month if month is not None else \"\"\n",
    "    suffix = suffix + \"_%s\" % program if program is not None else \"\"\n",
    "    print(suffix)\n",
    "    return suffix\n",
    "\n",
    "def data_quality_check(expanded_ct):\n",
    "    '''1. Delete rows where the mode_confirm was pilot_ebike and repalced_mode was pilot_ebike.\n",
    "       2. Delete rows where the mode_confirm was pilot_ebike and repalced_mode was same_mode.\n",
    "       3. Replace same_mode for the mode_confirm for Energy Impact Calcualtion.'''\n",
    "\n",
    "    # TODO: This is only really required for the initial data collection around the minipilot\n",
    "    # in subsequent deployes, we removed \"same mode\" and \"pilot_ebike\" from the options, so the\n",
    "    # dataset did not contain of these data quality issues\n",
    "\n",
    "    if 'replaced_mode' in expanded_ct.columns:\n",
    "        expanded_ct.drop(expanded_ct[(expanded_ct['mode_confirm'] == 'pilot_ebike') & (expanded_ct['replaced_mode'] == 'pilot_ebike')].index, inplace=True)\n",
    "        expanded_ct.drop(expanded_ct[(expanded_ct['mode_confirm'] == 'pilot_ebike') & (expanded_ct['replaced_mode'] == 'same_mode')].index, inplace=True)\n",
    "        expanded_ct['replaced_mode'] = np.where(expanded_ct['replaced_mode'] == 'same_mode',expanded_ct['mode_confirm'], expanded_ct['replaced_mode'])\n",
    "    \n",
    "    return expanded_ct\n",
    "\n",
    "def unit_conversions(df):\n",
    "    df['distance_miles']= df[\"distance\"]*0.00062 #meters to miles\n",
    "\n",
    "def energy_intensity(trip_df,mode_intensity_df,col):\n",
    "    \"\"\" Inputs:\n",
    "    trip_df = dataframe with data\n",
    "    mode_intensity_df = dataframe with energy/cost/time factors\n",
    "    col = the column for which we want to map the intensity\n",
    "    \"\"\"\n",
    "\n",
    "    mode_intensity_df = mode_intensity_df.copy()\n",
    "    mode_intensity_df[col] = mode_intensity_df['mode']\n",
    "    dic_ei_factor = dict(zip(mode_intensity_df[col],mode_intensity_df['energy_intensity_factor']))\n",
    "    dic_CO2_factor = dict(zip(mode_intensity_df[col],mode_intensity_df['CO2_factor']))\n",
    "    dic_ei_trip = dict(zip(mode_intensity_df[col],mode_intensity_df['(kWH)/trip']))\n",
    "\n",
    "    trip_df['ei_'+col] = trip_df[col].map(dic_ei_factor)\n",
    "    trip_df['CO2_'+col] = trip_df[col].map(dic_CO2_factor)\n",
    "    trip_df['ei_trip_'+col] = trip_df[col].map(dic_ei_trip)\n",
    "    return trip_df\n",
    "\n",
    "def energy_footprint_kWH(df,distance_miles,col):\n",
    "    \"\"\" Inputs:\n",
    "    df = dataframe with data\n",
    "    distance = distance in miles\n",
    "    col = Replaced_mode or Mode_confirm\n",
    "    \"\"\"\n",
    "    conditions_col = [(df[col+'_fuel'] =='gasoline'),\n",
    "                       (df[col+'_fuel'] == 'diesel'),\n",
    "                       (df[col+'_fuel'] == 'electric')]\n",
    "    gasoline_col = (df[distance_miles]*df['ei_'+col]*0.000293071) # 1 BTU = 0.000293071 kWH\n",
    "    diesel_col   = (df[distance_miles]*df['ei_'+col]*0.000293071)\n",
    "    electric_col = (df[distance_miles]*df['ei_'+col])+ df['ei_trip_'+col]\n",
    "    values_col = [gasoline_col,diesel_col,electric_col]\n",
    "    df[col+'_EI(kWH)'] = np.select(conditions_col, values_col)\n",
    "    return df\n",
    "\n",
    "def energy_impact_kWH(df,distance_miles):\n",
    "    if 'Mode_confirm_EI(kWH)' not in df.columns:\n",
    "        print(\"Mode confirm footprint not found, computing before impact\")\n",
    "        df = energy_footprint_kWH(df, distance_miles, \"Mode_confirm\")\n",
    "    df = energy_footprint_kWH(df, distance_miles, \"Replaced_mode\")\n",
    "    df['Energy_Impact(kWH)']  = round((df['Replaced_mode_EI(kWH)'] - df['Mode_confirm_EI(kWH)']),3)\n",
    "    return df\n",
    "\n",
    "def CO2_footprint_lb(df, distance_miles, col):\n",
    "    \"\"\" Inputs:\n",
    "    df = dataframe with data\n",
    "    distance = distance in miles\n",
    "    col = Replaced_mode or Mode_confirm\n",
    "    \"\"\"\n",
    "    conditions_col = [(df[col+'_fuel'] =='gasoline'),\n",
    "                       (df[col+'_fuel'] == 'diesel'),\n",
    "                       (df[col+'_fuel'] == 'electric')]\n",
    "   \n",
    "    gasoline_col = (df[distance_miles]*df['ei_'+col]*0.000001)* df['CO2_'+col]\n",
    "    diesel_col   = (df[distance_miles]*df['ei_'+col]*0.000001)* df['CO2_'+col]\n",
    "    electric_col = (((df[distance_miles]*df['ei_'+col])+df['ei_trip_'+col])*0.001)*df['CO2_'+col]\n",
    "\n",
    "    values_col = [gasoline_col,diesel_col,electric_col]\n",
    "    df[col+'_lb_CO2'] = np.select(conditions_col, values_col)\n",
    "    return df\n",
    "    \n",
    "def CO2_impact_lb(df,distance_miles):\n",
    "    if 'Mode_confirm_lb_CO2' not in df.columns:\n",
    "        print(\"Mode confirm footprint not found, computing before impact\")\n",
    "        df = CO2_footprint_lb(df, distance_miles, \"Mode_confirm\")\n",
    "    df = CO2_footprint_lb(df, distance_miles, \"Replaced_mode\")\n",
    "    df['CO2_Impact(lb)']  = round((df['Replaced_mode_lb_CO2'] - df['Mode_confirm_lb_CO2']),3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9079775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path configuration\n",
    "to_data_folder = \"PaperVizualizations/Data/abby_ceo/sc\" #data folder, where composite data was written from the TSDC_data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73190bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e99ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ct = pd.read_csv(to_data_folder + \"/analysis_confirmed_trip.csv\")\n",
    "# expanded_ct_2=pd.read_csv(to_data_folder + \"/tsdc_filtered_merged_trips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99cc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9e4da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Mode_confirm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda-23.5.2/envs/emission/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda-23.5.2/envs/emission/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda-23.5.2/envs/emission/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Mode_confirm'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m expanded_ct \u001b[38;5;241m=\u001b[39m \u001b[43madd_energy_impact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_ct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_ei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdic_fuel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expanded_ct) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m expanded_ct\n",
      "Cell \u001b[0;32mIn[9], line 164\u001b[0m, in \u001b[0;36madd_energy_impact\u001b[0;34m(expanded_ct, df_ei, dic_fuel)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_energy_impact\u001b[39m(expanded_ct, df_ei, dic_fuel):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# Let's first calculate everything for the mode confirm\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# And then calculate everything for the replaced mode\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     expanded_ct \u001b[38;5;241m=\u001b[39m \u001b[43madd_energy_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_ct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_ei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdic_fuel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     expanded_ct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReplaced_mode_fuel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m expanded_ct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReplaced_mode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(dic_fuel)\n\u001b[1;32m    166\u001b[0m     expanded_ct \u001b[38;5;241m=\u001b[39m energy_intensity(expanded_ct, df_ei, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReplaced_mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 155\u001b[0m, in \u001b[0;36madd_energy_labels\u001b[0;34m(expanded_ct, df_ei, dic_fuel)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_energy_labels\u001b[39m(expanded_ct, df_ei, dic_fuel):\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Inputs:\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    expanded_ct = dataframe of trips that has had Mode_confirm and Replaced_mode added\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    dic/df_* = label mappings for energy impact and fuel\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     expanded_ct[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMode_confirm_fuel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[43mexpanded_ct\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMode_confirm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(dic_fuel)\n\u001b[1;32m    156\u001b[0m     expanded_ct \u001b[38;5;241m=\u001b[39m energy_intensity(expanded_ct, df_ei, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMode_confirm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    157\u001b[0m     expanded_ct \u001b[38;5;241m=\u001b[39m energy_footprint_kWH(expanded_ct, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_miles\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMode_confirm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda-23.5.2/envs/emission/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda-23.5.2/envs/emission/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Mode_confirm'"
     ]
    }
   ],
   "source": [
    "expanded_ct = add_energy_impact(expanded_ct, df_ei, dic_fuel) if len(expanded_ct) > 0 else expanded_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "474938f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive.add_energy_labels(expanded_ct, df_ei, dic_fuel, [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
